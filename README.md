## Big Data Systems and Int Analytics

## Assignment2
- Goal: For this assignment you have to decouple the streamlit application from Assignment 1 into two microservice, Streamlit and FastAPI.

#### Team Information

| NAME                      |     NUID        |
|---------------------------|-----------------|
|   Raj Mehta               |   002743076     |
|   Mani Deepak Reddy Aila  |   002728148     |
|   Jared Videlefsky        |   001966442     |
|   Rumi Jha                |   002172213     |
 
 Submission Date: 24th February'23


#### CLAAT Link 
For Detail documentation- [Click here](https://codelabs-preview.appspot.com/?file_id=1jWZRlWLSZw73qNv_FUd2FOhLIxVbF2EclaAxaLFgOgk#8)

#### To Run:
`pip install -r requirements.txt`

`streamlit run 1_Login_Page.py`

`uvicorn apis:app --reload`

#### Files Description:
- Login_Page.py - This has code for the login/ registration user flow. It also has the streamlit code for the UI.
- SEVIRDataFetcher.py - This has functions to generate the url from filename. It also has the streamlit code for UI.
- NexradStations.py - streamlit code to plot the nexrad stations on map
- DbUtil.py - Utility class which has functions to create table, insert rows into table and to filter the data from tables.
- S3Util.py - Utility class to work with AWS S3
- aws_logging.py - To add cloudwatch logs on the users' request and the output
- apis.py - The FastAPIs used in the app.
- schemas.py - The response models used in the FastAPIs



## About

Implementing a a web app that fetches the metadata from the s3 bucket for NEXRAD data for the year 2023 and the Geos-18 for product RADC and the user can choose year/station/month/day of year/hour depending on the selection one would get file name dynamically from the s3 bucket. The user can download all files or download one file locally or push it to the s3 bucket.

Also, Great Expectation Library is implement is implemented inorder to check the purity of the data

Unit testing is done off all the links generated by user selection and also for a few pre-defined test cases

The nextrad station data is plotted on a map in the second page.


## Requirements

1. GEOS
    1. Explore and download selected datasets for the GOES satellite dataset
    2. Given a filename, construct the hyperlink of data location.
    3. Write Unit tests for all the use cases
    4. Test using the links from [Google-Docs-file](https://docs.google.com/spreadsheets/d/1o1CLsm5OR0gH5GHbTsPWAEOGpdqqS49-P5e14ugK37Q/edit#gid=0)
2. NexRad
    1. Explore and download selected datasets for the NexRad dataset
    2. Given a filename, construct the hyperlink of data location.
    3. Write Unit tests for all the use cases
    4. Test using the links from [Google-Docs-File](https://docs.google.com/spreadsheets/d/1o1CLsm5OR0gH5GHbTsPWAEOGpdqqS49-P5e14ugK37Q/edit#gid=0)
    5. Use a python package of your choice and plot the NexRad locations from [Nexrad-Wikipedia-Page](https://en.wikipedia.org/wiki/NEXRAD)

## Test Results

#### Creating script to fetch metadata from S3 and store it in a database along with fetching file names dynamically from the S3 bucket and then saving file to S3 user's bucket "Boto3"

## FastAPI

APIs:
- Login/ Registration:
- File Transfer:
- Get Filters:

## Docker

Containers:
- FastAPI Container - 
- Streamlit Container - 

## Airflow

TBD

## AWS Config

Utilized Amazon S3, Amazon IAM, and Amazon CloudWatch. Used Jared's AWS account as the root user and created a service account, DAMG_Service_Account, for the rest of the team. Service account has access to the necessary S3 buckets. Public users are able to download the transferred files from our S3 bucket.

### Storage - AWS S3
Stored files in AWS S3 buckets based on the datasource.

![image](https://user-images.githubusercontent.com/47637485/218146529-06bac511-193a-425a-91fa-82030dd9cc17.png)

### Logging - AWS CloudWatch
Logging was created with AWS CloudWatch. Logs contain a timestamp and a message. The messages we record are below:
- User Input
- Generated URL based off of the User Input
- User Action: Download Locally or Transfer to S3 Bucket

Example Logs:
![image](https://user-images.githubusercontent.com/47637485/217996246-a39d46e0-ad0d-445a-b9ea-296f1be21abf.png)

## SQLite Database

1. Imported the sqlite3 library ( can be installed using the command `pip install sqlite3`)
2. Sqlite Studio to work with the .db file (GUI)
3. Created 3 tables `geos18`, `nexrad` and `nexrad_lat_long`.
4. Utility class 'dbUtil' for functions like creating table, insertion of data into table and filter required data from table.

## Streamlit

We have implemented a Streamlit app to plot NexRad Radar Station in a frontend application.

Steps:
1. Import libraries (Streamlit, folium, Streamlit_foliumn) needed to plot the locations on map
2. Connect to the SQlite database and fetch data from nexrad_lat_long table having latitude and longitude detail of the location
3. Make use of folium function to plot the locations on map
4. Launch the web application by running `streamlit run NexRadRadarStations.py` script

The data in the image below shows location of current and archived radar stations. The map denotes these specified stations by a blue pin.
Additional information can be retrieved like the station name and city in which station is located by hovering over the points.
![image](https://user-images.githubusercontent.com/91744801/217998698-1e8d89ce-ed71-4a3e-8d77-dfc45a842986.jpg)

LIVE APPLICATION - [CLICK HERE](https://bigdataia-spring2023-team-03-assignment-sevirdatafetcher-k0tjb7.streamlit.app/)

## Attestation and Contribution Declaration:
Required attestation and contribution declaration on the GitHub page:
WE ATTEST THAT WE HAVEN’T USED ANY OTHER STUDENTS’ WORK IN OUR ASSIGNMENT
AND ABIDE BY THE POLICIES LISTED IN THE STUDENT HANDBOOK
- Raj Mehta - 25%
- Mani Deepak Reddy Aila - 25%
- Jared Videlefsky - 25%
- Rumi Jha - 25%


